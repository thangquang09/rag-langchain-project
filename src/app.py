import streamlit as st
from constant import models, model_kwargs
from file_loader import Loader, get_num_cpu, get_file_paths
from vectordb import VectorDatabase
from llm import get_local_model, get_api_model
from rag import RAG
from utils import select_running_type, initial_data, check_data_exists
from pydantic import BaseModel, Field
import time

class InputQA(BaseModel):
    question: str = Field(..., title="Question to ask the model")

class AnswerQA(BaseModel):
    answer: str = Field(..., title="Answer from the model")

# **H√†m giao di·ªán chat**
def chat_interface(rag_chain):
    st.title("AI Assistant")
    st.write("H·ªèi b·∫•t k·ª≥ c√¢u h·ªèi n√†o v√† nh·∫≠n c√¢u tr·∫£ l·ªùi t·ª´ tr·ª£ l√Ω AI.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ƒêang x·ª≠ l√Ω..."):
                start_time = time.time()
                user_question = InputQA(question=prompt)
                result = rag_chain(query=user_question.question)
                time_taken = time.time() - start_time
                answer = AnswerQA(answer=result)
                st.markdown(answer.answer)
                st.write(f"Th·ªùi gian x·ª≠ l√Ω: {time_taken:.2f} gi√¢y")

        st.session_state.messages.append({"role": "assistant", "content": answer.answer})

# **H√†m t·∫£i t√†i li·ªáu v·ªõi caching**
@st.cache_data
def load_documents(_loader, _file_paths, _workers):
    documents = _loader.load(_file_paths, workers=_workers)
    return documents

# **H√†m kh·ªüi t·∫°o vector database**
@st.cache_resource
def initialize_vectordb(_documents=None, load_new_vectordb=False, _cache_key=None):
    if _documents is not None and load_new_vectordb:
        vectordb = VectorDatabase(documents=_documents, load_new_vectordb=True)
    else:
        vectordb = VectorDatabase()
    return vectordb

# **H√†m ch·ªçn m√¥ h√¨nh c·ª•c b·ªô**
def select_model_interface():
    # Hi·ªÉn th·ªã danh s√°ch m√¥ h√¨nh c√≥ s·∫µn
    st.sidebar.subheader("M√¥ h√¨nh c·ª•c b·ªô")
    
    # Option 1: S·ª≠ d·ª•ng m√¥ h√¨nh c√≥ s·∫µn
    predefined_model = st.sidebar.selectbox(
        "Ch·ªçn m√¥ h√¨nh c√≥ s·∫µn:",
        options=[f"{i}: {model}" for i, model in enumerate(models)],
        index=0
    )
    
    # Option 2: Nh·∫≠p t√™n m√¥ h√¨nh Hugging Face t√πy ch·ªçn
    custom_model = st.sidebar.text_input("Ho·∫∑c nh·∫≠p t√™n m√¥ h√¨nh Hugging Face:", "")
    
    # X√°c ƒë·ªãnh m√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn
    if custom_model.strip():
        # N·∫øu ng∆∞·ªùi d√πng ƒë√£ nh·∫≠p t√™n m√¥ h√¨nh t√πy ch·ªçn
        return custom_model.strip()
    else:
        # L·∫•y index t·ª´ predefined_model (format: "0: mistralai/Mistral-7B-Instruct-v0.1")
        selected_index = int(predefined_model.split(":")[0])
        return models[selected_index]

# **H√†m ch√≠nh**
def main():
    st.set_page_config(
        page_title="AI Assistant",
        page_icon="üí¨",
        layout="wide"
    )
    # Check data and vector DB existence
    data_status = check_data_exists()
    
    # Handle different initialization scenarios
    if data_status != 0:
        message = {
            1: "ƒêang t·∫£i xu·ªëng d·ªØ li·ªáu PDF...",
            2: "ƒêang t·∫°o Vector Database...",
            3: "ƒêang t·∫£i xu·ªëng d·ªØ li·ªáu PDF v√† t·∫°o Vector Database..."
        }
        
        with st.spinner(message[data_status]):
            # Initialize data based on what's missing
            initial_data(data_status)
            
            success_message = {
                1: "ƒê√£ t·∫£i xu·ªëng d·ªØ li·ªáu PDF th√†nh c√¥ng!",
                2: "ƒê√£ t·∫°o Vector Database th√†nh c√¥ng!",
                3: "ƒê√£ kh·ªüi t·∫°o d·ªØ li·ªáu v√† Vector Database th√†nh c√¥ng!"
            }
            st.success(success_message[data_status])
    
    # Get file paths after initialization is complete (or if no initialization was needed)
    file_paths = get_file_paths()
    # Kh·ªüi t·∫°o session state
    if "model_loaded" not in st.session_state:
        st.session_state.model_loaded = False
        st.session_state.rag_chain = None
    
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    loader = Loader()

    # Trong m√£ ch√≠nh c·ªßa b·∫°n
    if st.sidebar.button("T·∫£i l·∫°i t√†i li·ªáu"):
        with st.spinner("ƒêang t·∫£i t√†i li·ªáu..."):
            load_documents.clear()  # X√≥a cache c≈© n·∫øu c√≥
            documents = load_documents(loader, file_paths, get_num_cpu())
            cache_key = time.time()  # T·∫°o m·ªôt kh√≥a duy nh·∫•t b·∫±ng timestamp
            vectordb = initialize_vectordb(_documents=documents, load_new_vectordb=True, _cache_key=cache_key)
    else:
        vectordb = initialize_vectordb()

    retriever = vectordb.get_retriever()

    # **Ch·ªçn lo·∫°i m√¥ h√¨nh**
    running_type = st.sidebar.radio("Ch·ªçn lo·∫°i m√¥ h√¨nh:", ("Local Model", "API Model"), index=0)
    
    # T·∫°o c√°c ph·∫ßn ch·ªçn m√¥ h√¨nh d·ª±a tr√™n lo·∫°i
    if running_type == "Local Model":
        model_name = select_model_interface()
    elif running_type == "API Model":
        model_name = "API Model"  # Placeholder for API model
    
    # T·∫°o n√∫t t·∫£i m√¥ h√¨nh
    if st.sidebar.button("T·∫£i v√† kh·ªüi ƒë·ªông m√¥ h√¨nh"):
        with st.spinner(f"ƒêang t·∫£i m√¥ h√¨nh {model_name}..."):
            # T·∫£i m√¥ h√¨nh ph√π h·ª£p
            if running_type == "Local Model":
                llm = get_local_model(model_name=model_name, **model_kwargs)
            elif running_type == "API Model":
                llm = get_api_model(**model_kwargs)
                
            # T·∫°o RAG Chain
            st.session_state.rag_chain = RAG(llm=llm).get_chain(retriever=retriever)
            st.session_state.model_loaded = True
            st.sidebar.success(f"ƒê√£ t·∫£i xong m√¥ h√¨nh {model_name}")
    
        # Th√™m n√∫t x√≥a l·ªãch s·ª≠ chat v√†o sidebar
    st.sidebar.markdown("---")
    st.sidebar.subheader("Qu·∫£n l√Ω cu·ªôc h·ªôi tho·∫°i")
    if st.sidebar.button("X√≥a l·ªãch s·ª≠ chat"):
        st.session_state.messages = []
        st.sidebar.success("ƒê√£ x√≥a l·ªãch s·ª≠ chat")
        st.rerun()  # Thay th·∫ø st.experimental_rerun() b·∫±ng st.rerun()

    # Hi·ªÉn th·ªã th√¥ng b√°o n·∫øu ch∆∞a t·∫£i m√¥ h√¨nh
    if not st.session_state.model_loaded:
        st.info("Vui l√≤ng ch·ªçn m√¥ h√¨nh v√† nh·∫•n 'T·∫£i v√† kh·ªüi ƒë·ªông m√¥ h√¨nh' ƒë·ªÉ b·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng.")
    else:
        # Load giao di·ªán chat
        chat_interface(st.session_state.rag_chain)

if __name__ == "__main__":
    main()